# receivers:
#   otlp:
#     protocols:
#       http:
#         endpoint: "0.0.0.0:4318"

# exporters:
#   debug:
#     verbosity: detailed
#   prometheus:
#     endpoint: "0.0.0.0:8888"
#   elasticsearch:
#     endpoint: "http://elasticsearch:9200"

# service:
#   pipelines:
#     metrics:
#       receivers: [otlp]
#       exporters: [debug, elasticsearch]

receivers:
  otlp:
    protocols:
      http:
        endpoint: "0.0.0.0:4318"  # OpenTelemetry Collector HTTP receiver
      grpc:
        endpoint: "0.0.0.0:55680"  # Optional OpenTelemetry gRPC receiver

exporters:
  debug:
    verbosity: detailed  # For detailed debugging information
  prometheus:
    endpoint: "0.0.0.0:8888"  # Prometheus metrics endpoint
  elasticsearch:
    endpoint: "http://elasticsearch:9200"  # Elasticsearch endpoint for traces
    index: "apm-traces"  # Index for traces
  otlp:
    endpoint: "jaeger:4319"  # Jaeger's OTLP gRPC endpoint (default for OTLP)

processors:
  batch:
    timeout: 10s  # Process spans in batches to improve performance
    send_batch_size: 512
    send_batch_max_size: 1024

service:
  pipelines:
    metrics:
      receivers: [otlp]
      exporters: [debug, elasticsearch]
    traces:
      receivers: [otlp]  # Set OTLP as the trace receiver
      processors: [batch]  # Batch processor to manage spans
      exporters: [debug, elasticsearch, otlp]  # Export to Jaeger (via OTLP), Elasticsearch, and debug